{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MTqRTLHeWvt6",
        "outputId": "c21da167-3415-487e-95d8-4492a3a66164"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<?xml version=\"1.0\" encoding=\"utf-8\"?>\r\n",
            "\r\n",
            "<!DOCTYPE html\r\n",
            "   PUBLIC \"-//W3C//DTD XHTML 1.0 Strict//EN\"\r\n",
            "   \"http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd\" >\r\n",
            "\r\n",
            "<html xmlns=\"http://www.w3.org/1999/xhtml\" lang=\"en\">\r\n",
            "  <head>\r\n",
            "    <title>\r\n",
            "      Moby Dick; Or the Whale, by Herman Melville\r\n",
            "    </title>\r\n",
            "    <style type=\"text/css\" xml:space=\"preserve\">\r\n",
            "\r\n",
            "    body { background:#faebd0; color:black; margin-left:15%; margin-right:15%; text-align:justify }\r\n",
            "    P { text-indent: 1em; margin-top: .25em; margin-bottom: .25em; }\r\n",
            "    H1,H2,H3,H4,H5,H6 { text-align: center; margin-left: 15%; margin-right: 15%; }\r\n",
            "    hr  { width: 50%; text-align: center;}\r\n",
            "    .foot { margin-left: 20%; margin-right: 20%; text-align: justify; text-indent: -3em; font-size: 90%; }\r\n",
            "    blockquote {font-size: 100%; margin-left: 0%; margin-right: 0%;}\r\n",
            "    .mynote    {background-color: #DDE; color: #000; padding: .5em; margin-left: 10%; margin-right: 10%; font-family: sans-serif; font-size: 95%;}\r\n",
            "    .toc       { margin-left: 10%; margin-bottom: .75em;}\r\n",
            "    .toc2      { margin-left: 20%;}\r\n",
            "    div.fig    { display:block; margin:0 auto; text-align:center; }\r\n",
            "    div.middle { margin-left: 20%; margin-right: 20%; text-align: justify; }\r\n",
            "    .figleft   {float: left; margin-left: 0%; margin-right: 1%;}\r\n",
            "    .figright  {float: right; margin-right: 0%; margin-left: 1%;}\r\n",
            "    .pagenum   {display:inline; font-size: 70%; font-style:normal;\r\n",
            "               margin: 0; padding: 0; position: absolute; right: 1%;\r\n",
            "               text-align: right;}\r\n",
            "    pre        { font-family: times new roman; font-size: 100%; margin-left: 10%;}\r\n",
            "\r\n",
            "    table      {margin-left: 10%;}\r\n",
            "\r\n",
            "a:link {color:blue;\r\n",
            "\t\ttext-decoration:none}\r\n",
            "link {color:blue;\r\n",
            "\t\ttext-decoration:none}\r\n",
            "a:visited {color:blue;\r\n",
            "\t\ttext-decoration:none}\r\n",
            "a:hover {color:red}\r\n",
            "\r\n",
            "</style>\r\n",
            "  </head>\r\n",
            "  <body>\r\n",
            "<pre xml:space=\"preserve\">\r\n",
            "\r\n",
            "The Project Gutenberg EBook of Moby Dick; or The Whale, by Herman Melville\r\n",
            "\r\n",
            "This eBook is for the use of anyone anywh\n",
            "[('whale', 1246), ('one', 925), ('like', 647), ('upon', 568), ('man', 527), ('ship', 519), ('ahab', 517), ('ye', 473), ('sea', 455), ('old', 452)]\n"
          ]
        }
      ],
      "source": [
        "# Import and download packages\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import nltk\n",
        "from collections import Counter\n",
        "nltk.download('stopwords')\n",
        "\n",
        "# Get the Moby Dick HTML\n",
        "r = requests.get('https://s3.amazonaws.com/assets.datacamp.com/production/project_147/datasets/2701-h.htm')\n",
        "\n",
        "# Set the correct text encoding of the HTML page\n",
        "r.encoding = 'utf-8'\n",
        "\n",
        "# Extract the HTML from the request object\n",
        "html = r.text\n",
        "\n",
        "# Print the first 2000 characters in html\n",
        "print(html[0:2000])\n",
        "\n",
        "# Create a BeautifulSoup object from the HTML\n",
        "html_soup = BeautifulSoup(html, \"html.parser\")\n",
        "\n",
        "# Get the text out of the soup\n",
        "moby_text = html_soup.get_text()\n",
        "\n",
        "# Create a tokenizer\n",
        "tokenizer = nltk.tokenize.RegexpTokenizer('\\w+')\n",
        "\n",
        "# Tokenize the text\n",
        "tokens = tokenizer.tokenize(moby_text)\n",
        "\n",
        "# Create a list called words containing all tokens transformed to lowercase\n",
        "words = [token.lower() for token in tokens]\n",
        "\n",
        "# Print out the first eight words\n",
        "words[:8]\n",
        "\n",
        "# Get the English stop words from nltk\n",
        "stop_words = nltk.corpus.stopwords.words('english')\n",
        "\n",
        "# Print out the first eight stop words\n",
        "stop_words[:8]\n",
        "\n",
        "# Create a list words_ns containing all words that are in words but not in stop_words\n",
        "words_no_stop = [word for word in words if word not in stop_words]\n",
        "\n",
        "# Print the first five words_no_stop to check that stop words are gone\n",
        "words_no_stop[:5]\n",
        "\n",
        "# Initialize a Counter object from our processed list of words\n",
        "count = Counter(words_no_stop)\n",
        "\n",
        "# Store ten most common words and their counts as top_ten\n",
        "top_ten = count.most_common(10)\n",
        "\n",
        "# Print the top ten words and their counts\n",
        "print(top_ten)"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ffM8f4qLWwwv"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}